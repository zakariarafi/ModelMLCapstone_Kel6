# -*- coding: utf-8 -*-
"""Drowsiness Detect_Casptone_Kelompok 6

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pfHiRnld9DD_-he_XAE04szaiGqXKvWS
"""

pip install matplotlib seaborn opencv-python numpy ultralytics

!pip install roboflow

from roboflow import Roboflow
rf = Roboflow(api_key="gXAVv17n0PwexK1g8kZE")
project = rf.workspace("study-ppql5").project("drowsiness-detection-2-ezliy-7lxam")
version = project.version(11)
dataset = version.download("yolov8")

import os
import cv2
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

from ultralytics import YOLO

from IPython.display import display, Image

import os
import cv2
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Path dataset dari Roboflow
DATASET_PATH = 'Drowsiness-Detection-2-10'
IMAGE_PATH = os.path.join(DATASET_PATH, 'train', 'images')
LABEL_PATH = os.path.join(DATASET_PATH, 'train', 'labels')

label_files = [f for f in os.listdir(LABEL_PATH) if f.endswith('.txt')]

class_counts = {}
bbox_areas = []

for label_file in label_files:
    with open(os.path.join(LABEL_PATH, label_file), 'r') as f:
        lines = f.readlines()
        for line in lines:
            if line.strip() == "":
                continue  # skip empty lines
            elements = line.strip().split()
            if len(elements) != 5:
                continue  # skip malformed lines

            class_id = int(elements[0])
            x_center, y_center, width, height = map(float, elements[1:])
            area = width * height
            bbox_areas.append(area)

            class_counts[class_id] = class_counts.get(class_id, 0) + 1

# Visualisasi distribusi kelas
plt.figure(figsize=(10, 5))
sns.barplot(x=list(class_counts.keys()), y=list(class_counts.values()))
plt.title("Distribusi Kelas (Jumlah BBox per Kelas)")
plt.xlabel("Class ID")
plt.ylabel("Jumlah")
plt.show()

# Visualisasi distribusi ukuran bbox
plt.figure(figsize=(10, 5))
sns.histplot(bbox_areas, bins=50, kde=True)
plt.title("Distribusi Luas Bounding Box")
plt.xlabel("Area (normalized)")
plt.ylabel("Frekuensi")
plt.show()

!yolo task=detect mode=train model=yolov8n.pt data='/content/Drowsiness-Detection-2-1/data.yaml' epochs=100 imgsz=360

!yolo task=detect mode=train model=yolov8n.pt data='/content/Drowsiness-Detection-2-11/data.yaml' epochs=120 imgsz=360

!yolo task=detect mode=val model='/content/runs/detect/train/weights/best.pt' data='/content/Drowsiness-Detection-2-10/data.yaml'

!yolo task=detect mode=predict model='/content/runs/detect/train/weights/best.pt' source='/WhatsApp Image 2025-05-03 at 20.05.33_8f82b9d2.jpg'

# Misalnya kamu menyimpan best.pt
model_path = '/content/runs/detect/train/weights/best.pt'

import torch
from ultralytics import YOLO
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- Load model ---
model = YOLO(model_path)

# --- Pruning (contoh sederhana dengan PyTorch) ---
def simple_prune_model(model, amount=0.2):
    """
    Prune model dengan menghilangkan 20% bobot terkecil pada semua Conv2d layers.
    """
    import torch.nn.utils.prune as prune

    logger.info("Mulai pruning model...")
    for name, module in model.model.named_modules():
        if isinstance(module, torch.nn.Conv2d):
            prune.l1_unstructured(module, name='weight', amount=amount)
            prune.remove(module, 'weight')  # Permanenkan pruning
    logger.info("Pruning selesai.")
    return model

# --- Quantization (static quantization example) ---
def quantize_model(model):
    """
    Quantize model menggunakan PyTorch static quantization.
    Hanya untuk CPU inference.
    """
    logger.info("Mulai quantization model...")

    model.model.eval()  # Harus eval dulu
    model.model = torch.quantization.quantize_dynamic(
        model.model,
        {torch.nn.Linear, torch.nn.Conv2d},
        dtype=torch.qint8
    )
    logger.info("Quantization selesai.")
    return model

# --- Terapkan pruning ---
pruned_model = simple_prune_model(model, amount=0.2)
pruned_model.save('/content/runs/detect/train/weights/best_pruned.pt')  # Format Ultralytics

# --- Terapkan quantization setelah pruning ---
quantized_model = quantize_model(pruned_model)
quantized_model.save('/content/runs/detect/train/weights/best_pruned_quantized.pt')  # Format Ultralytics

!yolo task=detect mode=val model='/content/runs/detect/train/weights/best_pruned.pt' data='/content/Drowsiness-Detection-2-10/data.yaml'

!yolo task=detect mode=val model='/content/runs/detect/train/weights/best_pruned_quantized.pt' data='/content/Drowsiness-Detection-2-10/data.yaml'

import requests

auth_token = "JMSJoJYzqTPfOYA6P3ywfot82MfIySRt"
value = "drowsy"  # hasil klasifikasi
pin = "V4"

url = f"https://blynk.cloud/external/api/update?token={auth_token}&{pin}={value}"
response = requests.get(url)

if response.status_code == 200:
    print("Berhasil kirim data ke Blynk:", value)
else:
    print("Gagal kirim:", response.text)

def eksekusi_dengan_toleransi(func, percobaan_maksimal=3, jeda_percobaan=5, *args, **kwargs):
    """Mengeksekusi fungsi dengan mekanisme percobaan ulang"""
    percobaan = 0
    while percobaan < percobaan_maksimal:
        try:
            logger.info(f"Mencoba menjalankan {func.__name__}, percobaan ke-{percobaan+1}")
            hasil = func(*args, **kwargs)
            logger.info(f"Fungsi {func.__name__} berhasil dijalankan")
            return hasil
        except Exception as e:
            percobaan += 1
            logger.error(f"Error saat menjalankan {func.__name__}: {str(e)}")
            logger.error(traceback.format_exc())

            if percobaan >= percobaan_maksimal:
                logger.critical(f"Fungsi {func.__name__} gagal setelah {percobaan_maksimal} kali percobaan")
                raise

            logger.info(f"Mencoba ulang dalam {jeda_percobaan} detik...")
            time.sleep(jeda_percobaan)

# Fungsi untuk menganalisis hasil dan menentukan status kantuk
def analisis_hasil_deteksi(hasil_path, ambang_batas_kantuk=0.6):
    try:
        # ... kode analisis ...
        return {
            "status": status,
            "skor_kantuk": skor_kantuk,
            "kepercayaan": tingkat_kepercayaan
        }
    except Exception as e:
        logger.error(f"Kesalahan saat menganalisis hasil: {str(e)}")
        # Nilai default yang aman - mengasumsikan kantuk sebagai tindakan pencegahan
        return {"status": "drowsy", "skor_kantuk": 1.0, "kepercayaan": 0.5}

import time
import logging
import traceback

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def eksekusi_dengan_toleransi(func, percobaan_maksimal=3, jeda_percobaan=5, *args, **kwargs):
    """Mengeksekusi fungsi dengan mekanisme percobaan ulang saat terjadi error."""
    percobaan = 0
    while percobaan < percobaan_maksimal:
        try:
            logger.info(f"Mencoba menjalankan {func.__name__}, percobaan ke-{percobaan + 1}")
            hasil = func(*args, **kwargs)
            logger.info(f"Fungsi {func.__name__} berhasil dijalankan")
            return hasil
        except Exception as e:
            percobaan += 1
            logger.error(f"Error saat menjalankan {func.__name__}: {str(e)}")
            logger.error(traceback.format_exc())

            if percobaan >= percobaan_maksimal:
                logger.critical(f"Fungsi {func.__name__} gagal setelah {percobaan_maksimal} kali percobaan")
                raise

            logger.info(f"Mencoba ulang dalam {jeda_percobaan} detik...")
            time.sleep(jeda_percobaan)

def train_model():
    !yolo task=detect mode=train model="/content/runs/detect/train/weights/best.pt" data='/content/Drowsiness-Detection-2-11/data.yaml' epochs=120 imgsz=360

eksekusi_dengan_toleransi(train_model, percobaan_maksimal=3, jeda_percobaan=10)

import torch
from ultralytics import YOLO
import time
import logging
import traceback
import requests

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- Load model ---
model_path = '/content/runs/detect/train/weights/best.pt'
model = YOLO(model_path)

# --- Pruning (contoh sederhana dengan PyTorch) ---
def simple_prune_model(model, amount=0.2):
    """
    Prune model dengan menghilangkan 20% bobot terkecil pada semua Conv2d layers.
    """
    import torch.nn.utils.prune as prune

    logger.info("Mulai pruning model...")
    for name, module in model.model.named_modules():
        if isinstance(module, torch.nn.Conv2d):
            prune.l1_unstructured(module, name='weight', amount=amount)
            prune.remove(module, 'weight')  # Apply pruning permanen
    logger.info("Pruning selesai.")
    return model

# --- Quantization (static quantization example) ---
def quantize_model(model):
    """
    Quantize model menggunakan PyTorch static quantization.
    Hanya untuk CPU inference.
    """
    logger.info("Mulai quantization model...")

    model.model.eval()  # Eval mode wajib sebelum quantization

    model_int8 = torch.quantization.quantize_dynamic(
        model.model,  # model PyTorch bawaan ultralytics
        {torch.nn.Linear, torch.nn.Conv2d},
        dtype=torch.qint8
    )
    logger.info("Quantization selesai.")
    return model_int8

# --- Terapkan pruning dan quantization ---
model = simple_prune_model(model, amount=0.2)
quantized_model = quantize_model(model)

# Kamu bisa simpan model hasil pruning dan quantization:
torch.save(model.model.state_dict(), '/content/runs/detect/train/weights/best_pruned.pt')
torch.save(quantized_model.state_dict(), '/content/runs/detect/train/weights/best_quantized.pt')

import time
import logging
import traceback
import requests

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def eksekusi_dengan_toleransi(func, percobaan_maksimal=3, jeda_percobaan=5, *args, **kwargs):
    """Mengeksekusi fungsi dengan mekanisme percobaan ulang saat terjadi error."""
    percobaan = 0
    while percobaan < percobaan_maksimal:
        try:
            logger.info(f"Mencoba menjalankan {func.__name__}, percobaan ke-{percobaan + 1}")
            hasil = func(*args, **kwargs)
            logger.info(f"Fungsi {func.__name__} berhasil dijalankan ✅")
            return hasil
        except Exception as e:
            percobaan += 1
            logger.error(f"❌ Error saat menjalankan {func.__name__}: {str(e)}")
            logger.error(traceback.format_exc())

            if percobaan >= percobaan_maksimal:
                logger.critical(f"🚨 Fungsi {func.__name__} gagal setelah {percobaan_maksimal} kali percobaan")
                raise

            logger.info(f"🔄 Mencoba ulang dalam {jeda_percobaan} detik...")
            time.sleep(jeda_percobaan)

def kirim_data_ke_blynk(value):
    auth_token = "JMSJoJYzqTPfOYA6P3ywfot82MfIySRt"  # Token Blynk terbaru
    pin = "V4"
    url = f"https://blynk.cloud/external/api/update?token={auth_token}&{pin}={value}"
    response = requests.get(url)
    if response.status_code == 200:
        logger.info(f"📡 Berhasil kirim data ke Blynk: {value}")
        return True
    else:
        raise Exception(f"Gagal kirim: {response.text}")

def analisis_hasil_deteksi(hasil_path, ambang_batas_kantuk=0.6):
    try:
        # ... kode analisis ...
        # Contoh dummy output untuk ilustrasi
        status = "awake"
        skor_kantuk = 0.2
        tingkat_kepercayaan = 0.85

        logger.info(f"Analisis berhasil: Status={status} 😎, Skor kantuk={skor_kantuk}, Kepercayaan={tingkat_kepercayaan}")
        return {
            "status": status,
            "skor_kantuk": skor_kantuk,
            "kepercayaan": tingkat_kepercayaan
        }
    except Exception as e:
        logger.error(f"⚠️ Kesalahan saat menganalisis hasil: {str(e)}")
        logger.info("Mengembalikan nilai default: status='drowsy' 😴, skor_kantuk=1.0, kepercayaan=0.5")
        # Nilai default yang aman - mengasumsikan kantuk sebagai tindakan pencegahan
        return {"status": "drowsy", "skor_kantuk": 1.0, "kepercayaan": 0.5}